"""
Streamlit Webç•Œé¢
ä¸ºMedia Agentæä¾›å‹å¥½çš„Webç•Œé¢
"""

import os
import sys
import streamlit as st
from datetime import datetime
import json
import locale
from loguru import logger

# è®¾ç½®UTF-8ç¼–ç ç¯å¢ƒ
os.environ['PYTHONIOENCODING'] = 'utf-8'
os.environ['PYTHONUTF8'] = '1'

# è®¾ç½®ç³»ç»Ÿç¼–ç 
try:
    locale.setlocale(locale.LC_ALL, 'en_US.UTF-8')
except locale.Error:
    try:
        locale.setlocale(locale.LC_ALL, 'C.UTF-8')
    except locale.Error:
        pass

# æ·»åŠ srcç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))

from MediaEngine import DeepSearchAgent, AnspireSearchAgent, Settings
from config import settings
from utils.github_issues import error_with_issue_link
import glob


def main():
    """ä¸»å‡½æ•°"""
    st.set_page_config(
        page_title="Media Agent",
        page_icon="",
        layout="wide"
    )

    st.title("Media Agent")
    st.markdown("å…·å¤‡å¼ºå¤§å¤šæ¨¡æ€èƒ½åŠ›çš„AIä»£ç†")
    st.markdown("çªç ´ä¼ ç»Ÿæ–‡æœ¬äº¤æµé™åˆ¶ï¼Œå¹¿æ³›çš„æµè§ˆæŠ–éŸ³ã€å¿«æ‰‹ã€å°çº¢ä¹¦çš„è§†é¢‘ã€å›¾æ–‡ã€ç›´æ’­")
    st.markdown("ä½¿ç”¨ç°ä»£åŒ–æœç´¢å¼•æ“æä¾›çš„è¯¸å¦‚æ—¥å†å¡ã€å¤©æ°”å¡ã€è‚¡ç¥¨å¡ç­‰å¤šæ¨¡æ€ç»“æ„åŒ–ä¿¡æ¯è¿›ä¸€æ­¥å¢å¼ºèƒ½åŠ›")

    # æ£€æŸ¥URLå‚æ•°
    try:
        # å°è¯•ä½¿ç”¨æ–°ç‰ˆæœ¬çš„query_params
        query_params = st.query_params
        auto_query = query_params.get('query', '')
        auto_search = query_params.get('auto_search', 'false').lower() == 'true'
    except AttributeError:
        # å…¼å®¹æ—§ç‰ˆæœ¬
        query_params = st.experimental_get_query_params()
        auto_query = query_params.get('query', [''])[0]
        auto_search = query_params.get('auto_search', ['false'])[0].lower() == 'true'

    # ----- é…ç½®è¢«ç¡¬ç¼–ç  -----
    # å¼ºåˆ¶ä½¿ç”¨ Gemini
    model_name = settings.MEDIA_ENGINE_MODEL_NAME or "gemini-2.5-pro"
    # é»˜è®¤é«˜çº§é…ç½®
    max_reflections = 2
    max_content_length = 20000

    # ç®€åŒ–çš„ç ”ç©¶æŸ¥è¯¢å±•ç¤ºåŒºåŸŸ

    # å¦‚æœæœ‰è‡ªåŠ¨æŸ¥è¯¢ï¼Œä½¿ç”¨å®ƒä½œä¸ºé»˜è®¤å€¼ï¼Œå¦åˆ™æ˜¾ç¤ºå ä½ç¬¦
    display_query = auto_query if auto_query else "ç­‰å¾…ä»ä¸»é¡µé¢æ¥æ”¶åˆ†æå†…å®¹..."

    # åªè¯»çš„æŸ¥è¯¢å±•ç¤ºåŒºåŸŸ
    st.text_area(
        "å½“å‰æŸ¥è¯¢",
        value=display_query,
        height=100,
        disabled=True,
        help="æŸ¥è¯¢å†…å®¹ç”±ä¸»é¡µé¢çš„æœç´¢æ¡†æ§åˆ¶",
        label_visibility="hidden"
    )

    # è‡ªåŠ¨æœç´¢é€»è¾‘
    start_research = False
    query = auto_query

    if auto_search and auto_query and 'auto_search_executed' not in st.session_state:
        st.session_state.auto_search_executed = True
        start_research = True
    elif auto_query and not auto_search:
        st.warning("ç­‰å¾…æœç´¢å¯åŠ¨ä¿¡å·...")

    # éªŒè¯é…ç½®
    if start_research:
        if not query.strip():
            st.error("è¯·è¾“å…¥ç ”ç©¶æŸ¥è¯¢")
            logger.error("è¯·è¾“å…¥ç ”ç©¶æŸ¥è¯¢")
            return

        # ç”±äºå¼ºåˆ¶ä½¿ç”¨Geminiï¼Œæ£€æŸ¥ç›¸å…³çš„APIå¯†é’¥
        if not settings.MEDIA_ENGINE_API_KEY:
            st.error("è¯·åœ¨æ‚¨çš„ç¯å¢ƒå˜é‡ä¸­è®¾ç½®MEDIA_ENGINE_API_KEY")
            logger.error("è¯·åœ¨æ‚¨çš„ç¯å¢ƒå˜é‡ä¸­è®¾ç½®MEDIA_ENGINE_API_KEY")
            return

        # è‡ªåŠ¨ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„APIå¯†é’¥
        engine_key = settings.MEDIA_ENGINE_API_KEY
        bocha_key = settings.BOCHA_WEB_SEARCH_API_KEY
        ansire_key = settings.ANSPIRE_API_KEY

        # æ„å»º Settingsï¼ˆpydantic_settingsé£æ ¼ï¼Œä¼˜å…ˆå¤§å†™ç¯å¢ƒå˜é‡ï¼‰
        if settings.SEARCH_TOOL_TYPE == "BochaAPI":
            if not bocha_key:
                st.error("è¯·åœ¨æ‚¨çš„ç¯å¢ƒå˜é‡ä¸­è®¾ç½®BOCHA_WEB_SEARCH_API_KEY")
                logger.error("è¯·åœ¨æ‚¨çš„ç¯å¢ƒå˜é‡ä¸­è®¾ç½®BOCHA_WEB_SEARCH_API_KEY")
                return
            logger.info("ä½¿ç”¨Bochaæœç´¢APIå¯†é’¥")
            config = Settings(
                MEDIA_ENGINE_API_KEY=engine_key,
                MEDIA_ENGINE_BASE_URL=settings.MEDIA_ENGINE_BASE_URL,
                MEDIA_ENGINE_MODEL_NAME=model_name,
                SEARCH_TOOL_TYPE="BochaAPI",
                BOCHA_WEB_SEARCH_API_KEY=bocha_key,
                MAX_REFLECTIONS=max_reflections,
                SEARCH_CONTENT_MAX_LENGTH=max_content_length,
                OUTPUT_DIR="media_engine_streamlit_reports",
            )
        elif settings.SEARCH_TOOL_TYPE == "AnspireAPI":
            if not ansire_key:
                st.error("è¯·åœ¨æ‚¨çš„ç¯å¢ƒå˜é‡ä¸­è®¾ç½®ANSPIRE_API_KEY")
                logger.error("è¯·åœ¨æ‚¨çš„ç¯å¢ƒå˜é‡ä¸­è®¾ç½®ANSPIRE_API_KEY")
                return
            logger.info("ä½¿ç”¨Anspireæœç´¢APIå¯†é’¥")
            config = Settings(
                MEDIA_ENGINE_API_KEY=engine_key,
                MEDIA_ENGINE_BASE_URL=settings.MEDIA_ENGINE_BASE_URL,
                MEDIA_ENGINE_MODEL_NAME=model_name,
                SEARCH_TOOL_TYPE="AnspireAPI",
                ANSPIRE_API_KEY=ansire_key,
                MAX_REFLECTIONS=max_reflections,
                SEARCH_CONTENT_MAX_LENGTH=max_content_length,
                OUTPUT_DIR="media_engine_streamlit_reports",
            )
        else:
            st.error(f"æœªçŸ¥çš„æœç´¢å·¥å…·ç±»å‹: {settings.SEARCH_TOOL_TYPE}")
            logger.error(f"æœªçŸ¥çš„æœç´¢å·¥å…·ç±»å‹: {settings.SEARCH_TOOL_TYPE}")
            return

        # æ‰§è¡Œç ”ç©¶
        execute_research(query, config)
    
    # å¦‚æœå·²æœ‰ç ”ç©¶ç»“æœï¼Œé‡æ–°æ˜¾ç¤ºï¼ˆé˜²æ­¢é¡µé¢åˆ·æ–°åä¸¢å¤±ï¼‰
    elif st.session_state.get('research_completed') and st.session_state.get('final_report'):
        st.success("ç ”ç©¶å·²å®Œæˆï¼")
        
        # æ·»åŠ é‡ç½®æŒ‰é’®
        col1, col2 = st.columns([3, 1])
        with col2:
            if st.button("ğŸ”„ å¼€å§‹æ–°ç ”ç©¶", key="reset_btn", type="primary"):
                # æ¸…ç©ºå…³é”®çš„ session state
                keys_to_clear = ['research_completed', 'final_report', 'agent', 
                                'auto_search_executed', 'history_report_content']
                for key in keys_to_clear:
                    if key in st.session_state:
                        del st.session_state[key]
                st.rerun()
        
        st.header("ç ”ç©¶ç»“æœ")
        st.markdown(st.session_state.final_report)
        
        # æ˜¾ç¤º agent è¯¦æƒ…ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        if st.session_state.get('agent'):
            agent = st.session_state.agent
            with st.expander("æŸ¥çœ‹è¯¦ç»†ä¿¡æ¯"):
                for i, paragraph in enumerate(agent.state.paragraphs):
                    st.write(f"**æ®µè½ {i + 1}: {paragraph.title}**")
                    summary = paragraph.research.latest_summary
                    st.write(summary[:500] + "..." if len(summary) > 500 else summary)
                    st.divider()
    
    # å†å²æŠ¥å‘ŠåŠ è½½åŠŸèƒ½
    load_history_reports("media_engine_streamlit_reports")


def load_history_reports(reports_dir: str):
    """åŠ è½½å¹¶æ˜¾ç¤ºå†å²æŠ¥å‘Š"""
    st.divider()
    
    # è·å–æŠ¥å‘Šæ–‡ä»¶åˆ—è¡¨
    report_pattern = os.path.join(reports_dir, "deep_search_report_*.md")
    report_files = sorted(glob.glob(report_pattern), key=os.path.getmtime, reverse=True)
    
    if not report_files:
        with st.expander("ğŸ“‚ å†å²æŠ¥å‘Šï¼ˆæš‚æ— ï¼‰"):
            st.info("æš‚æ— å†å²æŠ¥å‘Šã€‚å®Œæˆç ”ç©¶åï¼ŒæŠ¥å‘Šå°†è‡ªåŠ¨ä¿å­˜åœ¨æ­¤ã€‚")
        return
    
    with st.expander(f"ğŸ“‚ å†å²æŠ¥å‘Šï¼ˆ{len(report_files)} ä»½ï¼‰"):
        # åˆ›å»ºé€‰æ‹©å™¨
        report_names = []
        for f in report_files[:10]:  # æœ€å¤šæ˜¾ç¤º10ä»½
            basename = os.path.basename(f)
            mtime = datetime.fromtimestamp(os.path.getmtime(f))
            report_names.append(f"{basename} ({mtime.strftime('%m-%d %H:%M')})")
        
        selected = st.selectbox(
            "é€‰æ‹©è¦æŸ¥çœ‹çš„æŠ¥å‘Š",
            options=range(len(report_names)),
            format_func=lambda x: report_names[x],
            key="history_report_selector"
        )
        
        if st.button("ğŸ“– åŠ è½½æŠ¥å‘Š", key="load_history_btn"):
            try:
                with open(report_files[selected], 'r', encoding='utf-8') as f:
                    content = f.read()
                st.session_state.history_report_content = content
            except Exception as e:
                st.error(f"è¯»å–æŠ¥å‘Šå¤±è´¥: {e}")
        
        # æ˜¾ç¤ºå·²åŠ è½½çš„å†å²æŠ¥å‘Š
        if st.session_state.get('history_report_content'):
            st.markdown("---")
            st.markdown(st.session_state.history_report_content)


def execute_research(query: str, config: Settings):
    """æ‰§è¡Œç ”ç©¶"""
    try:
        # åˆ›å»ºè¿›åº¦æ¡
        progress_bar = st.progress(0)
        status_text = st.empty()

        # åˆå§‹åŒ–Agent
        status_text.text("æ­£åœ¨åˆå§‹åŒ–Agent...")
        if config.SEARCH_TOOL_TYPE == "BochaAPI":
            agent = DeepSearchAgent(config)
        elif config.SEARCH_TOOL_TYPE == "AnspireAPI":
            agent = AnspireSearchAgent(config)
        else:
            raise ValueError(f"æœªçŸ¥çš„æœç´¢å·¥å…·ç±»å‹: {config.SEARCH_TOOL_TYPE}")
        st.session_state.agent = agent

        progress_bar.progress(10)

        # ç”ŸæˆæŠ¥å‘Šç»“æ„
        status_text.text("æ­£åœ¨ç”ŸæˆæŠ¥å‘Šç»“æ„...")
        agent._generate_report_structure(query)
        progress_bar.progress(20)

        # å¤„ç†æ®µè½
        total_paragraphs = len(agent.state.paragraphs)
        for i in range(total_paragraphs):
            status_text.text(f"æ­£åœ¨å¤„ç†æ®µè½ {i + 1}/{total_paragraphs}: {agent.state.paragraphs[i].title}")

            # åˆå§‹æœç´¢å’Œæ€»ç»“
            agent._initial_search_and_summary(i)
            progress_value = 20 + (i + 0.5) / total_paragraphs * 60
            progress_bar.progress(int(progress_value))

            # åæ€å¾ªç¯
            agent._reflection_loop(i)
            agent.state.paragraphs[i].research.mark_completed()

            progress_value = 20 + (i + 1) / total_paragraphs * 60
            progress_bar.progress(int(progress_value))

        # ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š
        status_text.text("æ­£åœ¨ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š...")
        logger.info("æ­£åœ¨ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š...")
        final_report = agent._generate_final_report()
        progress_bar.progress(90)

        # ä¿å­˜æŠ¥å‘Š
        status_text.text("æ­£åœ¨ä¿å­˜æŠ¥å‘Š...")
        logger.info("æ­£åœ¨ä¿å­˜æŠ¥å‘Š...")
        agent._save_report(final_report)
        progress_bar.progress(100)

        status_text.text("ç ”ç©¶å®Œæˆï¼")
        logger.info("ç ”ç©¶å®Œæˆï¼")
        
        # ä¿å­˜ç»“æœåˆ° session stateï¼Œé˜²æ­¢é¡µé¢åˆ·æ–°åä¸¢å¤±
        st.session_state.final_report = final_report
        st.session_state.research_completed = True
        
        # æ˜¾ç¤ºç»“æœ
        display_results(agent, final_report)

    except Exception as e:
        import traceback
        error_traceback = traceback.format_exc()
        error_display = error_with_issue_link(
            f"ç ”ç©¶è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}",
            error_traceback,
            app_name="Media Engine Streamlit App"
        )
        st.error(error_display)
        logger.exception(f"ç ”ç©¶è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")


def display_results(agent: DeepSearchAgent, final_report: str):
    """æ˜¾ç¤ºç ”ç©¶ç»“æœ"""
    st.header("ç ”ç©¶ç»“æœ")

    # ç»“æœæ ‡ç­¾é¡µï¼ˆå·²ç§»é™¤ä¸‹è½½é€‰é¡¹ï¼‰
    tab1, tab2 = st.tabs(["ç ”ç©¶å°ç»“", "å¼•ç”¨ä¿¡æ¯"])

    with tab1:
        st.markdown(final_report)

    with tab2:
        # æ®µè½è¯¦æƒ…
        st.subheader("æ®µè½è¯¦æƒ…")
        for i, paragraph in enumerate(agent.state.paragraphs):
            with st.expander(f"æ®µè½ {i + 1}: {paragraph.title}"):
                st.write("**é¢„æœŸå†…å®¹:**", paragraph.content)
                st.write("**æœ€ç»ˆå†…å®¹:**", paragraph.research.latest_summary[:300] + "..."
                if len(paragraph.research.latest_summary) > 300
                else paragraph.research.latest_summary)
                st.write("**æœç´¢æ¬¡æ•°:**", paragraph.research.get_search_count())
                st.write("**åæ€æ¬¡æ•°:**", paragraph.research.reflection_iteration)

        # æœç´¢å†å²
        st.subheader("æœç´¢å†å²")
        all_searches = []
        for paragraph in agent.state.paragraphs:
            all_searches.extend(paragraph.research.search_history)

        if all_searches:
            for i, search in enumerate(all_searches):
                query_label = search.query if search.query else "æœªè®°å½•æŸ¥è¯¢"
                with st.expander(f"æœç´¢ {i + 1}: {query_label}"):
                    paragraph_title = getattr(search, "paragraph_title", "") or "æœªæ ‡æ³¨æ®µè½"
                    search_tool = getattr(search, "search_tool", "") or "æœªæ ‡æ³¨å·¥å…·"
                    has_result = getattr(search, "has_result", True)
                    st.write("**æ®µè½:**", paragraph_title)
                    st.write("**ä½¿ç”¨çš„å·¥å…·:**", search_tool)
                    preview = search.content or ""
                    if not isinstance(preview, str):
                        preview = str(preview)
                    if len(preview) > 200:
                        preview = preview[:200] + "..."
                    st.write("**URL:**", search.url or "æ— ")
                    st.write("**æ ‡é¢˜:**", search.title or "æ— ")
                    st.write("**å†…å®¹é¢„è§ˆ:**", preview if preview else "æ— å¯ç”¨å†…å®¹")
                    if not has_result:
                        st.info("æœ¬æ¬¡æœç´¢æœªè¿”å›ç»“æœ")
                    if search.score:
                        st.write("**ç›¸å…³åº¦è¯„åˆ†:**", search.score)


if __name__ == "__main__":
    main()
